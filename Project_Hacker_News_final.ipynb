{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Analysis - Dataquest Practice Project\n",
    "\n",
    "This data analysis project focuses analysing two types of Hacker News posts: _\"Ask HN\"_ and _\"Show HN\"_\n",
    "\n",
    "The focus of the analysis is the following:\n",
    "\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "The data set used in the analysis can be downloaded from [Kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts/data)\n",
    "\n",
    "The data set includes the following information:\n",
    "\n",
    "|column|description|\n",
    "|:---|:---|\n",
    "|id|The unique identifier from Hacker News for the post|\n",
    "|title|The title of the post|\n",
    "|url|The URL that the posts links to, if it the post has a URL|\n",
    "|num_points|The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes|\n",
    "|num_comments|The number of comments that were made on the post|\n",
    "|author|The username of the person who submitted the post|\n",
    "|created_at|The date and time at which the post was submitted|\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data file is first read in as a list of list. The data set has almost 300 000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n",
      "\n",
      "\n",
      "Number of rows in the data set: 293119\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "opened_file = open('HN_posts_year_to_Sep_26_2016.csv', encoding='utf8')\n",
    "read_file = csv.reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0] # header saved to individual variable\n",
    "hn = hn[1:] # header removed from data set\n",
    "\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[:5])\n",
    "print('\\n')\n",
    "print('Number of rows in the data set:', len(hn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into three separate data sets. The data set includes c. 9000 \"Ask HN\" posts and c. 10 000 \"Show HN\" posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']]\n",
      "\n",
      "\n",
      "[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']]\n",
      "\n",
      "\n",
      "Number of rows in ask_posts: 9139\n",
      "Number of rows in show_posts: 10158\n",
      "Number of rows in other_posts: 282961\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower() # the titles are transformed into lower case\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    if title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(ask_posts[:3])\n",
    "print('\\n')\n",
    "print(show_posts[:3])\n",
    "print('\\n')\n",
    "print('Number of rows in ask_posts:', len(ask_posts))\n",
    "print('Number of rows in show_posts:', len(show_posts))\n",
    "print('Number of rows in other_posts:', len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next the number of comments \"Ask HN\" posts and \"Show HN\" posts have received in total is analyzed. On average \"Ask HN\" posts get twice the amount of comments compared to \"Show HN\" comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments per \"Ask HN\" post\": 10.393478498741656\n",
      "Average comments per \"Show HN\" post\": 4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "# calculation of average comments per \"Ask HN\" posts\n",
    "\n",
    "total_ask_comments = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments.append(num_comments)\n",
    "\n",
    "avg_ask_comments = sum(total_ask_comments)/len(total_ask_comments)\n",
    "\n",
    "print('Average comments per \"Ask HN\" post\":', avg_ask_comments)\n",
    "\n",
    "# calculation of average comments per \"Show HN\" posts\n",
    "\n",
    "total_show_comments = []\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments.append(num_comments)\n",
    "\n",
    "avg_show_comments = sum(total_show_comments)/len(total_show_comments)\n",
    "\n",
    "print('Average comments per \"Show HN\" post\":', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further analysis is limited to \"Ask HN\" posts, as they have received the most comments on average. The analysis focuses on the question if posts posted at certain times of the day receive more comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['9/26/2016 2:53', 7], ['9/26/2016 1:17', 3], ['9/25/2016 22:57', 0], ['9/25/2016 22:48', 3], ['9/25/2016 21:50', 2]]\n",
      "\n",
      "\n",
      "Number of \"Ask HN\" posts by hour: {2: 270, 1: 283, 22: 384, 21: 519, 19: 553, 17: 588, 15: 647, 14: 514, 13: 445, 11: 313, 10: 283, 9: 223, 7: 227, 3: 272, 23: 344, 20: 511, 16: 580, 8: 258, 0: 302, 18: 615, 12: 343, 4: 244, 6: 235, 5: 210}\n",
      "\n",
      "\n",
      "\"Ask HN\" posts, received comments by hour: {2: 3003, 1: 2092, 22: 3372, 21: 4502, 19: 3955, 17: 5550, 15: 18525, 14: 4972, 13: 7247, 11: 2799, 10: 3013, 9: 1574, 7: 1589, 3: 2155, 23: 2297, 20: 4462, 16: 4466, 8: 2369, 0: 2279, 18: 4889, 12: 4240, 4: 2362, 6: 1588, 5: 1838}\n",
      "\n",
      "\n",
      "Average number of comments per post by hour: [[2, 11.122222222222222], [1, 7.392226148409894], [22, 8.78125], [21, 8.67437379576108], [19, 7.151898734177215], [17, 9.438775510204081], [15, 28.632148377125194], [14, 9.673151750972762], [13, 16.285393258426968], [11, 8.942492012779553], [10, 10.646643109540635], [9, 7.058295964125561], [7, 7.0], [3, 7.922794117647059], [23, 6.6773255813953485], [20, 8.731898238747554], [16, 7.7], [8, 9.182170542635658], [0, 7.546357615894039], [18, 7.949593495934959], [12, 12.361516034985423], [4, 9.680327868852459], [6, 6.757446808510639], [5, 8.752380952380953]]\n"
     ]
    }
   ],
   "source": [
    "# datetime module used for the analysis of dates and times\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "result_list = [] # data used in the analysis isolated to a new list\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments])\n",
    "\n",
    "print(result_list[:5])\n",
    "print('\\n')\n",
    "\n",
    "counts_by_hour = {} # information about number of posts and comments colleted into dictionaries\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    created_at = row[0]\n",
    "    dt_created_at = dt.datetime.strptime(created_at, '%m/%d/%Y %H:%M')\n",
    "    dt_created_time = dt_created_at.time()\n",
    "    dt_created_hour = dt_created_time.hour\n",
    "    if dt_created_hour not in counts_by_hour:\n",
    "        counts_by_hour[dt_created_hour] = 1\n",
    "        comments_by_hour[dt_created_hour] = row[1]\n",
    "    if dt_created_hour in counts_by_hour:\n",
    "        counts_by_hour[dt_created_hour] += 1\n",
    "        comments_by_hour[dt_created_hour] += row[1]\n",
    "\n",
    "print('Number of \"Ask HN\" posts by hour:', counts_by_hour)\n",
    "print('\\n')\n",
    "print('\"Ask HN\" posts, received comments by hour:', comments_by_hour)\n",
    "    \n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour and comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "print('\\n')\n",
    "print('Average number of comments per post by hour:', avg_by_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average values are then sorted and top 5 hours are printed. \"Ask HN\" posts have received most comments at 15:00, 13:00, 12:00, 2:00 and 10:00. The top 3 hours are in the afternoon. The hours are in US eastern time zone ([data description](https://www.kaggle.com/hacker-news/hacker-news-posts/data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.122222222222222, 2], [7.392226148409894, 1], [8.78125, 22], [8.67437379576108, 21], [7.151898734177215, 19], [9.438775510204081, 17], [28.632148377125194, 15], [9.673151750972762, 14], [16.285393258426968, 13], [8.942492012779553, 11], [10.646643109540635, 10], [7.058295964125561, 9], [7.0, 7], [7.922794117647059, 3], [6.6773255813953485, 23], [8.731898238747554, 20], [7.7, 16], [9.182170542635658, 8], [7.546357615894039, 0], [7.949593495934959, 18], [12.361516034985423, 12], [9.680327868852459, 4], [6.757446808510639, 6], [8.752380952380953, 5]]\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.63 average comments per posts\n",
      "13:00: 16.29 average comments per posts\n",
      "12:00: 12.36 average comments per posts\n",
      "02:00: 11.12 average comments per posts\n",
      "10:00: 10.65 average comments per posts\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "print('\\n')\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    datetime = dt.datetime.strptime(str(row[1]), '%H')\n",
    "    dt_time = datetime.time()\n",
    "    formatted_time = dt_time.strftime('%H:%M')\n",
    "    result_text = '{hour}: {posts:.2f} average comments per posts'.format(hour = formatted_time, posts = row[0])\n",
    "    print(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted to the time zone of Finland, the top 5 hours for Ask Posts Comments are in the evening and in the morning. So a post written at 22:00, 20:00, 19:00, 2:00 or 17:00 is more likely to receive comments than posts written at other hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments converted to Finnish time\n",
      "22:00: 28.63 average comments per posts\n",
      "20:00: 16.29 average comments per posts\n",
      "19:00: 12.36 average comments per posts\n",
      "09:00: 11.12 average comments per posts\n",
      "17:00: 10.65 average comments per posts\n"
     ]
    }
   ],
   "source": [
    "print('Top 5 Hours for Ask Posts Comments converted to Finnish time')\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    datetime = dt.datetime.strptime(str(row[1] + 7), '%H') # time difference between Easter US and Finland is 7 hours \n",
    "    dt_time = datetime.time()\n",
    "    formatted_time = dt_time.strftime('%H:%M')\n",
    "    result_text = '{hour}: {posts:.2f} average comments per posts'.format(hour = formatted_time, posts = row[0])\n",
    "    print(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
